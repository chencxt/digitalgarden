---
{"dg-publish":true,"permalink":"/05publishedweb/W002-学习进度/241116_-1_进度搬运_第3个校园团队项目_工业设备齿轮箱状态预测与故障诊断SVM分类模型/","noteIcon":"","created":"2025-03-15T10:29:25.868+08:00","updated":"2025-03-15T11:15:53.218+08:00"}
---


**天津工业大学**

控制科学与工程学院

**实**

**验**

**报**

**告**

课程名称： 模式识别与机器学习

上课时间：2024至2025学年（春/秋）学期

班 级： 自动化2202

姓 名： 陈星佟

学 号： 2210410224

评 分：

**一、实验目的**

（1）正文宋体四号，首行缩进2字符，单倍行距；

（2）图片需进行标号，如“图1 实验电路图”，宋体小四居中；

（3）表格需进行标号，如“表1 实验结果”，三线表宋体小四；

（4）实验目的参考实验指导书。

利用齿轮箱不同部位加速传感器采集到的3种状态下齿轮箱的震动信号，使用机器学习方法，建立预测与诊断模型，实现齿轮箱运行状态识别与故障诊断。

**二、实验内容**

1.数据清洗

工业数据往往存在异常值，会对后续处理产生影响，需要对初始数据进行数据清洗，包括异常值处理、缺失值插补等，选择相应方法处理。例如：采用Z分数法进行异常值查询，再对缺失值进行均值插补。

记录错误数据位置以及修正前后的数据值。

2.数据分析

数据集为振动信号数据，对其进行计算分析，如波形指标、脉冲指标、裕度指标等，观察正常数据和故障数据的区别。计算两组数据的以下指标，并自行查阅其他至少5种描述信号特征的指标，计算并记录在表格后：

3.异常数据判断

通过合适的方法区分异常数据和正常数据，例如：

通过统计方法，基于PCA，采用T2和SPE统计量对处理后数据进行检测。分辨出大于阈值的异常数据点，建立异常数据和正常数据样本集。

4.故障识别和数据集建立

选取合适的方法（如聚类、按特征值分类等），区分2类故障数据，制作标签。整合带标签的正常和异常数据，设计机器学习的训练集和测试集，记录训练集和测试集数据量。

5.故障诊断

选取合适的方法建立故障诊断模型，使用测试集验证模型。记录混淆矩阵图，标题为“班级-姓名-学号”，记录预测准确率。

**三、实验步骤**

```matlab
%第一步：数据清洗

% 读取Excel文件中的数据

filename = 'original_data.xlsx';

data = readmatrix(filename);

% 初始化记录修正信息的表格

correctionLog = [];

% 设置Z分数阈值

zThreshold = 3;

% 遍历每一列数据

for col = 1:size(data, 2)

% 计算每列数据的Z分数

colData = data(:, col);

zScores = (colData - mean(colData, 'omitnan')) / std(colData, 'omitnan');

% 找到异常值的位置

outliers = abs(zScores) > zThreshold;

% 记录异常值信息

for row = find(outliers)'

originalValue = colData(row);

% 使用均值插补修正异常值

colData(row) = mean(colData(~outliers), 'omitnan');

correctedValue = colData(row);

% 添加到修正日志

correctionLog = [correctionLog; {size(correctionLog, 1) + 1, sprintf('(%d,%d)', row, col), originalValue, correctedValue}];

end

% 处理缺失值（NaN）

nanIndices = isnan(colData);

for row = find(nanIndices)'

originalValue = NaN;

% 使用均值插补修正缺失值

colData(row) = mean(colData(~nanIndices), 'omitnan');

correctedValue = colData(row);

% 添加到修正日志

correctionLog = [correctionLog; {size(correctionLog, 1) + 1, sprintf('(%d,%d)', row, col), originalValue, correctedValue}];

end

% 更新数据列

data(:, col) = colData;

end

% 将修正日志写入Excel文件

correctionLogTable = cell2table(correctionLog, 'VariableNames', {'Number', 'DataLabel', 'OriginalData', 'CorrectedData'});

writetable(correctionLogTable, 'correction_log.xlsx');

% 将清洗后的数据写回Excel文件

writematrix(data, 'cleaned_gearbox_vibration_data.xlsx');

%第二步：数据分析

% 读取cleaned_gearbox_vibration_data.xlsx文件

cleanedData = readmatrix('cleaned_gearbox_vibration_data.xlsx');

% 读取correction_log.xlsx文件，跳过表头

correctionLog = readtable('correction_log.xlsx');

originalData1 = correctionLog.OriginalData; % 第三列数据

correctedData2 = correctionLog.CorrectedData; % 第四列数据

% 定义计算指标的函数，未指定参数的，一律使用默认值

calculateMetrics = @(data) struct(...

'mean', mean(data, 'omitnan'), ...

'rms', rms(data, 'omitnan'), ...

'peak', max(abs(data), [], 'omitnan'), ...

'crestFactor', max(abs(data), [], 'omitnan') / rms(data, 'omitnan'), ...

'formFactor', rms(data, 'omitnan') / mean(abs(data), 'omitnan'), ...

'impulseFactor', max(abs(data), [], 'omitnan') / mean(abs(data), 'omitnan'), ...

'peakFactor', max(abs(data), [], 'omitnan') / mean(data.^2, 'omitnan'), ...

'kurtosis', kurtosis(data(~isnan(data))) ...

);

% 计算各类指标

metricsSensor1 = calculateMetrics(cleanedData(:, 1));

metricsOriginalData1 = calculateMetrics(originalData1);

metricsSensor2 = calculateMetrics(cleanedData(:, 2));

metricsCorrectedData2 = calculateMetrics(correctedData2);

% 创建输出表格

outputTable = table({'平均值'; '均方根值'; '峰值'; '裕度指标'; '波形指标'; '脉冲指标'; '峰值指标'; '峭度指标'}, ...

[metricsSensor1.mean; metricsSensor1.rms; metricsSensor1.peak; metricsSensor1.crestFactor; metricsSensor1.formFactor; metricsSensor1.impulseFactor; metricsSensor1.peakFactor; metricsSensor1.kurtosis], ...

[metricsOriginalData1.mean; metricsOriginalData1.rms; metricsOriginalData1.peak; metricsOriginalData1.crestFactor; metricsOriginalData1.formFactor; metricsOriginalData1.impulseFactor; metricsOriginalData1.peakFactor; metricsOriginalData1.kurtosis], ...

[metricsSensor2.mean; metricsSensor2.rms; metricsSensor2.peak; metricsSensor2.crestFactor; metricsSensor2.formFactor; metricsSensor2.impulseFactor; metricsSensor2.peakFactor; metricsSensor2.kurtosis], ...

[metricsCorrectedData2.mean; metricsCorrectedData2.rms; metricsCorrectedData2.peak; metricsCorrectedData2.crestFactor; metricsCorrectedData2.formFactor; metricsCorrectedData2.impulseFactor; metricsCorrectedData2.peakFactor; metricsCorrectedData2.kurtosis], ...

'VariableNames', {'指标', 'Sensor1_cleaned', 'OriginalData1', 'Sensor2_cleaned', 'CorrectedData2'});

% 将结果写入Excel文件

writetable(outputTable, 'analysis_results_with_additional_metrics.xlsx');

% 可视化数据

figure;

subplot(2, 1, 1);

plot(cleanedData(:, 1));

title('Sensor1 - Cleaned Data');

xlabel('Sample');

ylabel('Amplitude');

subplot(2, 1, 2);

plot(cleanedData(:, 2));

title('Sensor2 - Cleaned Data');

xlabel('Sample');

ylabel('Amplitude');

% 如果需要对比原始和修正后的数据

figure;

subplot(2, 1, 1);

plot(originalData1, 'r');

title('Original Data1 - Correction Log');

xlabel('Sample');

ylabel('Amplitude');

subplot(2, 1, 2);

plot(correctedData2, 'b');

title('Corrected Data2 - Correction Log');

xlabel('Sample');

ylabel('Amplitude');

%第三步：异常数据判断

% 读取数据

cleanedData = readmatrix('cleaned_gearbox_vibration_data.xlsx');

% 标准化数据

standardizedData = zscore(cleanedData);

% 执行 PCA

[coeff, score, latent, ~, explained] = pca(standardizedData);

% 选择主成分数量（选择解释90%方差的主成分）

cumulativeVariance = cumsum(explained);

numComponents = find(cumulativeVariance >= 90, 1);

% 计算 T^2 统计量

T2 = sum((score(:, 1:numComponents) / diag(latent(1:numComponents))).^2, 2);

% 计算 SPE 统计量

reconstructedData = score(:, 1:numComponents) * coeff(:, 1:numComponents)';

residuals = standardizedData - reconstructedData;

SPE = sum(residuals.^2, 2);

% 确定 T^2 和 SPE 的阈值

alpha = 0.05; % 显著性水平

T2_threshold = chi2inv(1 - alpha, numComponents);

SPE_threshold = mean(SPE) + 3 * std(SPE);

% 输出阈值到命令行窗口

fprintf('T2_threshold: %.7e\n', T2_threshold);

fprintf('SPE_threshold: %.7e\n', SPE_threshold);

% 标记异常点

isT2Outlier = T2 > T2_threshold;

isSPEOutlier = SPE > SPE_threshold;

isOutlier = isT2Outlier | isSPEOutlier;

% 分离正常和异常数据

normalData = cleanedData(~isOutlier, :);

outlierData = cleanedData(isOutlier, :);

% 输出结果

writematrix(normalData, 'normal_data.xlsx');

writematrix(outlierData, 'outlier_data.xlsx');

% 可视化结果

figure;

subplot(2, 1, 1);

plot(T2);

hold on;

yline(T2_threshold, 'r--', 'T^2 Threshold');

title('Hotelling''s T^2 Statistic');

xlabel('Sample');

ylabel('T^2 Value');

legend('T^2', 'Threshold');

subplot(2, 1, 2);

plot(SPE);

hold on;

yline(SPE_threshold, 'r--', 'SPE Threshold');

title('Squared Prediction Error (SPE)');

xlabel('Sample');

ylabel('SPE Value');

legend('SPE', 'Threshold');

%第四步：故障识别和数据集建立

% 读取正常和异常数据

normalData = readmatrix('normal_data.xlsx');

outlierData = readmatrix('outlier_data.xlsx');

% 合并数据

allData = [normalData; outlierData];

% 设置聚类数量（2类：正常和异常）

numClusters = 2;

% 使用我们较为熟悉的 K-means 聚类方法作为训练集的制作方案

[idx, ~] = kmeans(allData, numClusters);

% 制作标签

% 假设正常数据在 normalData 中，异常数据在 outlierData 中

% 我们需要根据 idx 的结果来确定哪个簇是正常的，哪个是异常的

% 这里假设 idx(1:size(normalData, 1)) 的多数为正常

normalCluster = mode(idx(1:size(normalData, 1)));

labels = (idx == normalCluster); % 正常为 1，异常为 0

% 添加标签到数据

labeledData = [allData, labels];

% 划分训练集和测试集

% 使用 70% 的数据作为训练集，30% 作为测试集

cv = cvpartition(size(labeledData, 1), 'HoldOut', 0.3);

trainData = labeledData(training(cv), :);

testData = labeledData(test(cv), :);

% 记录训练集和测试集数据量

trainSize = size(trainData, 1);

testSize = size(testData, 1);

% 输出训练集和测试集数据量

fprintf('Training set size: %d\n', trainSize);

fprintf('Test set size: %d\n', testSize);

% 将训练集和测试集写入 Excel 文件

writematrix(trainData, 'train_data.xlsx');

writematrix(testData, 'test_data.xlsx');

%第五步：故障诊断

% 读取训练集和测试集

trainData = readmatrix('train_data.xlsx');

testData = readmatrix('test_data.xlsx');

% 分离特征和标签

X_train = trainData(:, 1:end-1);

y_train = trainData(:, end);

X_test = testData(:, 1:end-1);

y_test = testData(:, end);

% 训练SVM模型，线性核函数(专用于二分类学习)(高斯核、线性核、多项式核)，标准化预测变量数据(中心缩放)

SVMModel = fitcsvm(X_train, y_train, 'KernelFunction', 'linear', 'Standardize', true);

% 使用测试集进行预测

y_pred = predict(SVMModel, X_test);

% 计算混淆矩阵

confMat = confusionmat(y_test, y_pred);

% 计算预测准确率

accuracy = sum(y_pred == y_test) / length(y_test);

% 输出预测准确率

fprintf('Prediction Accuracy: %.4f\n', accuracy * 100);

% 绘制混淆矩阵图

figure;

confChart = confusionchart(y_test, y_pred, ...

'Title', '班级-姓名-学号', ...

'RowSummary', 'row-normalized', ...

'ColumnSummary', 'column-normalized');

% 设置图表标题

title('班级:自动化2202-姓名:陈星佟-学号:2210410224');

% 保存SVM模型到文件

modelFilename = 'SVMModel3.mat';

saveCompactModel(SVMModel, modelFilename);

fprintf('SVM model saved to %s\n', modelFilename);

这个方案的区别在于，K-means用于分类的簇从两个变成了三个，这样对调参具有更高的要求。SVM核函数从线性换成了高斯核，可以适应更好地适应小样本波动系数大的情况。但是根据实际情况，一次三分类方案更符合实际，输出的混淆矩阵也就更加直观，但是这里依旧将其弃用，原因有二：

1. 两者的代码量和内存使用量差不多，二次二分类需要计算两次，一次三分类仅需一次。虽然一次三分类比二次二分类方案的计算量少一点（大致在2-3秒的差距），但是对于小样本问题，二者差距不大。
2. 虽然理论上一次三分类更直观可靠，但是由于参数要求比二次二分类更高，所以在参数整定的时候遇到了不小的麻烦，截至到实验结束，我也只调整训练出来了一次超过85%准确率的模型。

![05publishedweb/W002-学习进度/DocxerAttachments/Attachment 36.png](/img/user/05publishedweb/W002-%E5%AD%A6%E4%B9%A0%E8%BF%9B%E5%BA%A6/DocxerAttachments/Attachment%2036.png)

图11:一次三分类方案SVM模型输出的混淆矩阵

从此图的八个一次三分类方案输出的SVM模型预测混淆矩阵可以看出，从统计学分析上讲，模型总体估计准确率收敛于40%-80%区间，偶尔出现过几次超过85%的情况，但并不多。其实理论上可以通过整定参数，把模型的准确率提升到90%以上，但是二次二分类的鲁棒性明显更好，且本人嫌调整参数太麻烦，所以最终实验方案选择了二次二分类。

但是，如果出现了中大型模型（3-5GB及以上）训练需求，二次二分类肯定就不如一次三分类更加高效了。那时候就需要细致地对参数进行调整，以将其准确率提上去。

上图二行二列的混淆矩阵结果，命令行窗口输出如下：

T2_threshold: 5.9914645e+00

SPE_threshold: 5.7989793e-30

Prediction Accuracy: 88.92%

SVM model saved to SVMModel3.mat

**本次实验也证明了：“在小样本区间，Bi-K-means分类训练的模型素质对照K-means具有更好的预测效果”。**

在实验最后总结分析中，我们发现了参数也对模型具有深远影响。在数据清洗与特征提取中，Z 分数阈值用于识别异常值。阈值越低，检测到的异常值越多，可能导致过多的数据被标记为异常；阈值越高，可能漏掉一些真正的异常值。在特征选择中，选择的特征（如均方根值、裕度指标等）直接影响模型的性能和准确性。不同的特征可以提供不同的故障信息。在异常检测中，PCA 矩阵元素数量影响 T² 和 SPE 统计量的计算。选择过少的组件可能导致信息丢失，过多的组件可能引入噪声。其中，T² 和 SPE 阈值，用于识别异常数据点。阈值的选择会影响异常检测的灵敏度和特异性。在聚类与分类中，K-means 聚类数量直接决定数据被分为多少类。错误的聚类数量可能导致错误的分类。在训练中，SVM 核函数决定了数据在高维空间中的映射方式，影响分类边界的形状和模型的复杂性。常用的核函数包括高斯核、线性核、RBF 核等。RBF 核通常适用于非线性数据。SVM 正则化参数（BoxConstraint）控制模型的复杂性和过拟合。较大的值可能导致过拟合，较小的值可能导致欠拟合，我们可以通过交叉验证或网格搜索来选择合适的参数。在模型验证中，训练集与测试集划分比例会影响模型的训练和验证效果。过小的训练集可能导致模型欠拟合，过小的测试集可能导致验证不充分。  

1. 请附各部分程序源代码。

答：详见上文第三部分实验步骤。

1. 请在心得体会中根据立项报告内容与实验情况进行对比，分析一下实验方法还有哪些可以改进的地方；结合调研过程，谈谈对解决实际工程问题有哪些理解。

答：本次实验验证了基于机器学习的故障诊断方法的可行性和有效性，但在实际应用中，仍有许多方向需要改进，比如适应数据来源的多样性和复杂性、加强模型的实时性与计算效率、加强模型的适应性和鲁棒性等等。通过深入的调研与实验探索，我对故障诊断模型的工程实现有了更深刻的理解。未来的研究可以进一步探索特征提取、模型优化和系统架构改进，进而提升模型的工业应用价值。比如，尽管 SVM 在分类上表现良好，但其对于复杂的非线性特征的表现仍有局限性。在工业实际场景中，故障信号常常表现出非线性和非平稳特征。可以考虑引入深度学习方法（如卷积神经网络 CNN 或长短期记忆网络 LSTM），以自动提取复杂特征，提高模型的适应性。可以通过交叉验证和网格搜索进一步优化 SVM 超参数，以提升模型的表现。但本次实验的我们能力有限，能实现的方案较少，往以后继续精进技术水平。